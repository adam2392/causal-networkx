{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# An introduction to causal graphs and how to use them\n\nCausal graphs are graphical objects that attach causal notions to each edge\nand missing edge. We will review some of the fundamental causal graphs used\nin causal inference, and their differences using implementations in ``causal-networkx``.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Adam Li <adam2392@gmail.com>\n#\n# License: BSD (3-clause)\n\nimport numpy as np\n\nfrom causal_networkx import CPDAG, PAG, StructuralCausalModel\nfrom causal_networkx.algorithms import d_separated\nfrom causal_networkx.ci import Oracle\nfrom causal_networkx.discovery import PC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Structural Causal Models: Simulating some data\n\nStructural causal models (SCMs) :footcite:`Pearl_causality_2009` are mathematical objects\ndefined by a 4-tuple <V, U, F, P(U)>, where:\n\n  - V is the set of endogenous observed variables\n  - U is the set of exogenous unobserved variables\n  - F is the set of functions for every $v \\in V$\n  - P(U) is the set of distributions for all $u \\in U$\n\nTaken together, these four objects define the generating causal\nmechanisms for a causal problem. Almost always, the SCM is not known.\nHowever, the SCM induces a causal graph, which has nodes from ``V``\nand then edges are defined by the arguments of the functions in ``F``.\nIf there are common exogenous parents for any V, then this can be represented\nin an Acyclic Directed Mixed Graph (ADMG), or a causal graph with bidirected edges.\nThe common latent confounder is represented with a bidirected edge between two\nendogenous variables.\n\nEven though the SCM is typically unknown, we can still use it to generate\nground-truth simulations to evaluate various algorithms and build our intuition.\nHere, we will simulate some data to understand causal graphs in the context of SCMs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# set a random seed to make example reproducible\nseed = 12345\nrng = np.random.RandomState(seed=seed)\n\n# construct a SCM with 2 exogenous variables and 4 endogenous variables\n# x, xy, z -> y; xy -> x\nfunc_uz = lambda: rng.binomial(n=1, p=0.25)\nfunc_ux = lambda: rng.binomial(n=1, p=0.25)\nfunc_uxy = lambda: rng.binomial(n=1, p=0.4)\nfunc_xy = lambda u_xy: u_xy\nfunc_x = lambda u_x, xy: 2 * u_x + xy\nfunc_y = lambda x, xy, z: x * xy + z\nfunc_z = lambda u_z: u_z\n\n# construct the SCM\nscm = StructuralCausalModel(\n    exogenous={\n        \"u_xy\": func_uxy,\n        \"u_z\": func_uz,\n        \"u_x\": func_ux,\n    },\n    endogenous={\"x\": func_x, \"y\": func_y, \"z\": func_z, \"xy\": func_xy},\n)\n\n# sample the incomplete observational data\ndata = scm.sample(n=5000, include_latents=False)\n\n# We can now get the induced causal graph, which is a causal DAG\n# in this case, since there are no exogenous confounders.\n# We then say the SCM is \"Markovian\".\nG = scm.get_causal_graph()\n\n# note the graph shows colliders, which is a collision of arrows\n# for example between ``x`` and ``z`` at ``y``.\nG.draw()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Causal Directed Ayclic Graphs (DAG): Also known as Causal Bayesian Networks\n\nCausal DAGs represent Markovian SCMs, also known as the \"causally sufficient\"\nassumption, where there are no unobserved confounders in the graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(G)\n\n# One can query the parents of 'y' for example\nprint(list(G.parents(\"y\")))\n\n# Or the children of 'xy'\nprint(list(G.children(\"xy\")))\n\n# Using the graph, we can explore d-separation statements, which by the Markov\n# condition, imply conditional independences.\n# For example, 'z' is d-separated from 'x' because of the collider at 'y'\nprint(f\"'z' is d-separated from 'x': {d_separated(G, 'z', 'x')}\")\n\n# Conditioning on the collider, opens up the path\nprint(f\"'z' is d-separated from 'x' given 'y': {d_separated(G, 'z', 'x', 'y')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Acyclic Directed Mixed Graphs (ADMG)\n\nADMGs represent Semi-Markovian SCMs, where there are possibly unobserved confounders\nin the graph. These unobserved confounders are graphically depicted with a bidirected edge.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We can construct an ADMG from the DAG by just setting 'xy' as a latent confounder\nadmg = G.set_nodes_as_latent_confounders([\"xy\"])\n\n# Now there is a bidirected edge between 'x' and 'y'\nadmg.draw()\n\n# Now if one queries the parents of 'y', it will not show 'xy' anymore\nprint(list(admg.parents(\"y\")))\n\n# The bidirected edges also form a cluster in what is known as \"confounded-components\", or\n# c-components for short.\nprint(f\"The ADMG has c-components: {admg.c_components}\")\n\n# We can also look at d-separation statements similarly to a DAG.\n# For example, 'z' is still d-separated from 'x' because of the collider at 'y'\nprint(f\"'z' is d-separated from 'x': {d_separated(admg, 'z', 'x')}\")\n\n# Conditioning on the collider, opens up the path\nprint(f\"'z' is d-separated from 'x' given 'y': {d_separated(admg, 'z', 'x', 'y')}\")\n\n# Say we add a bidirected edge between 'z' and 'x', then they are no longer\n# d-separated.\nadmg.add_bidirected_edge(\"z\", \"x\")\nprint(f\"'z' is d-separated from 'x': {d_separated(admg, 'z', 'x')}\")\n\n# Markov Equivalence Classes\n# --------------------------\n#\n# Besides graphs that represent causal relationships from the SCM, there are other\n# graphical objects used in the causal inference literature.\n#\n# Markov equivalence class graphs are graphs that encode the same Markov equivalences\n# or d-separation statements, or conditional independences. These graphs are commonly\n# used in constraint-based structure learning algorithms, which seek to reconstruct\n# parts of the causal graph from data. In this next section, we will briefly overview\n# some of these common graphs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Completed Partially Directed Ayclic Graph (CPDAG)\nCPDAGs are Markov Equivalence class graphs that encode the same d-separation statements\nas a causal DAG that stems from a Markovian SCM. All relevant variables are assumed to\nbe observed. An uncertain edge orientation is encoded via a undirected edge between two\nvariables. Here, we'll construct a CPDAG that encodes the same d-separations as the\nearlier DAG.\n\nTypically, CPDAGs are learnt using some variant of the PC algorithm :footcite:`Spirtes1993`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cpdag = CPDAG()\n\n# let's assume all the undirected edges are formed from the earlier DAG\ncpdag.add_undirected_edges_from(G.edges)\n\n# next, we will orient all unshielded colliders present in the original DAG\ncpdag.orient_undirected_edge(\"x\", \"y\")\ncpdag.orient_undirected_edge(\"xy\", \"y\")\ncpdag.orient_undirected_edge(\"z\", \"y\")\n\n# Note: the CPDAG orients all edges that participate in an unshielded collider.\n# The only non-oriented edge is between 'xy' and 'x'. We can\n# run the full PC algorithm using the oracle graph, and verify the output.\npc = PC(ci_estimator=Oracle(G))\npc.fit(data)\ngraph_ = pc.graph_\n\n# The two graphs match exactly\nprint(graph_.all_edges())\nprint(cpdag.all_edges())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Partial Ancestral Graph (PAG)\nPAGs are Markov equivalence classes for ADMGs. Since we allow latent confounders, these graphs\nare more complex compared to the CPDAGs. PAGs encode uncertain edge orientations via circle\nendpoints. A circle endpoint (``o-*``) can imply either: a tail (``-*``), or an arrowhead (``<-*``),\nwhich can then imply either an undirected edge (selection bias), directed edge (ancestral relationship),\nor bidirected edge (possible presence of a latent confounder).\n\nNote: a directed edge in the PAG does not actually imply parental relationships.\n\nTypically, PAGs are learnt using some variant of the FCI algorithm :footcite:`Spirtes1993` and\n:footcite`Zhang2008`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pag = PAG()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### References\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}