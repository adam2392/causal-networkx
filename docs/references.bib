% Encoding: UTF-8

@article{Colombo2012,
  author    = {Diego Colombo and Marloes H. Maathuis and Markus Kalisch and Thomas S. Richardson},
  title     = {{Learning high-dimensional directed acyclic graphs with latent and selection variables}},
  volume    = {40},
  journal   = {The Annals of Statistics},
  number    = {1},
  publisher = {Institute of Mathematical Statistics},
  pages     = {294 -- 321},
  keywords  = {Causal structure learning, consistency, FCI algorithm, high-dimensionality, maximal ancestral graphs (MAGs), partial ancestral graphs (PAGs), RFCI algorithm, Sparsity},
  year      = {2012},
  doi       = {10.1214/11-AOS940},
  url       = {https://doi.org/10.1214/11-AOS940}
}

@article{Zhang2008,
  title    = {On the completeness of orientation rules for causal discovery in the presence of latent confounders and selection bias},
  journal  = {Artificial Intelligence},
  volume   = {172},
  number   = {16},
  pages    = {1873-1896},
  year     = {2008},
  issn     = {0004-3702},
  doi      = {https://doi.org/10.1016/j.artint.2008.08.001},
  url      = {https://www.sciencedirect.com/science/article/pii/S0004370208001008},
  author   = {Jiji Zhang},
  keywords = {Ancestral graphs, Automated causal discovery, Bayesian networks, Causal models, Markov equivalence, Latent variables},
  abstract = {Causal discovery becomes especially challenging when the possibility of latent confounding and/or selection bias is not assumed away. For this task, ancestral graph models are particularly useful in that they can represent the presence of latent confounding and selection effect, without explicitly invoking unobserved variables. Based on the machinery of ancestral graphs, there is a provably sound causal discovery algorithm, known as the FCI algorithm, that allows the possibility of latent confounders and selection bias. However, the orientation rules used in the algorithm are not complete. In this paper, we provide additional orientation rules, augmented by which the FCI algorithm is shown to be complete, in the sense that it can, under standard assumptions, discover all aspects of the causal structure that are uniquely determined by facts of probabilistic dependence and independence. The result is useful for developing any causal discovery and reasoning system based on ancestral graph models.}
}

@book{Neapolitan2003,
  author = {Neapolitan, Richard},
  year   = {2003},
  month  = {01},
  pages  = {},
  title  = {Learning Bayesian Networks},
  isbn   = {9780123704771},
  doi    = {10.1145/1327942.1327961}
}

@book{Spirtes1993,
  author  = {Spirtes, Peter and Glymour, Clark and Scheines, Richard},
  year    = {1993},
  month   = {01},
  pages   = {},
  title   = {Causation, Prediction, and Search},
  volume  = {81},
  isbn    = {978-1-4612-7650-0},
  journal = {Causation, Prediction, and Search},
  doi     = {10.1007/978-1-4612-2748-9}
}
