% Encoding: UTF-8
% Try to keep this list in alphabetical order based on citing name

@article{Colombo2012,
  author    = {Diego Colombo and Marloes H. Maathuis and Markus Kalisch and Thomas S. Richardson},
  title     = {{Learning high-dimensional directed acyclic graphs with latent and selection variables}},
  volume    = {40},
  journal   = {The Annals of Statistics},
  number    = {1},
  publisher = {Institute of Mathematical Statistics},
  pages     = {294 -- 321},
  keywords  = {Causal structure learning, consistency, FCI algorithm, high-dimensionality, maximal ancestral graphs (MAGs), partial ancestral graphs (PAGs), RFCI algorithm, Sparsity},
  year      = {2012},
  doi       = {10.1214/11-AOS940},
  url       = {https://doi.org/10.1214/11-AOS940}
}

@book{Neapolitan2003,
  author    = {Neapolitan, Richard},
  year      = {2003},
  month     = {01},
  pages     = {},
  title     = {Learning Bayesian Networks},
  isbn      = {9780123704771},
  publisher = {Pearson},
  doi       = {10.1145/1327942.1327961}
}

 @article{Runge_pcmci_2019,
  author   = {Jakob Runge  and Peer Nowack  and Marlene Kretschmer  and Seth Flaxman  and Dino Sejdinovic },
  title    = {Detecting and quantifying causal associations in large nonlinear time series datasets},
  journal  = {Science Advances},
  volume   = {5},
  number   = {11},
  pages    = {eaau4996},
  year     = {2019},
  doi      = {10.1126/sciadv.aau4996},
  url      = {https://www.science.org/doi/abs/10.1126/sciadv.aau4996},
  eprint   = {https://www.science.org/doi/pdf/10.1126/sciadv.aau4996},
  abstract = {A novel causal discovery method for estimating nonlinear interdependency networks from large time series datasets. Identifying causal relationships and quantifying their strength from observational time series data are key problems in disciplines dealing with complex dynamical systems such as the Earth system or the human body. Data-driven causal inference in such systems is challenging since datasets are often high dimensional and nonlinear with limited sample sizes. Here, we introduce a novel method that flexibly combines linear or nonlinear conditional independence tests with a causal discovery algorithm to estimate causal networks from large-scale time series datasets. We validate the method on time series of well-understood physical mechanisms in the climate system and the human heart and using large-scale synthetic datasets mimicking the typical properties of real-world data. The experiments demonstrate that our method outperforms state-of-the-art techniques in detection power, which opens up entirely new possibilities to discover and quantify causal networks from time series across a range of research fields.}
}

 @book{Spirtes1993,
  author    = {Spirtes, Peter and Glymour, Clark and Scheines, Richard},
  year      = {1993},
  month     = {01},
  pages     = {},
  title     = {Causation, Prediction, and Search},
  volume    = {81},
  isbn      = {978-1-4612-7650-0},
  doi       = {10.1007/978-1-4612-2748-9},
  publisher = {The MIT Press}
}

@article{Zhang2008,
  title    = {On the completeness of orientation rules for causal discovery in the presence of latent confounders and selection bias},
  journal  = {Artificial Intelligence},
  volume   = {172},
  number   = {16},
  pages    = {1873-1896},
  year     = {2008},
  issn     = {0004-3702},
  doi      = {https://doi.org/10.1016/j.artint.2008.08.001},
  url      = {https://www.sciencedirect.com/science/article/pii/S0004370208001008},
  author   = {Jiji Zhang},
  keywords = {Ancestral graphs, Automated causal discovery, Bayesian networks, Causal models, Markov equivalence, Latent variables},
  abstract = {Causal discovery becomes especially challenging when the possibility of latent confounding and/or selection bias is not assumed away. For this task, ancestral graph models are particularly useful in that they can represent the presence of latent confounding and selection effect, without explicitly invoking unobserved variables. Based on the machinery of ancestral graphs, there is a provably sound causal discovery algorithm, known as the FCI algorithm, that allows the possibility of latent confounders and selection bias. However, the orientation rules used in the algorithm are not complete. In this paper, we provide additional orientation rules, augmented by which the FCI algorithm is shown to be complete, in the sense that it can, under standard assumptions, discover all aspects of the causal structure that are uniquely determined by facts of probabilistic dependence and independence. The result is useful for developing any causal discovery and reasoning system based on ancestral graph models.}
}

@inproceedings{Zhang2011,
  author    = {Zhang, Kun and Peters, Jonas and Janzing, Dominik and Sch\"{o}lkopf, Bernhard},
  title     = {Kernel-Based Conditional Independence Test and Application in Causal Discovery},
  year      = {2011},
  isbn      = {9780974903972},
  publisher = {AUAI Press},
  address   = {Arlington, Virginia, USA},
  abstract  = {Conditional independence testing is an important problem, especially in Bayesian network learning and causal discovery. Due to the curse of dimensionality, testing for conditional independence of continuous variables is particularly challenging. We propose a Kernel-based Conditional Independence test (KCI-test), by constructing an appropriate test statistic and deriving its asymptotic distribution under the null hypothesis of conditional independence. The proposed method is computationally efficient and easy to implement. Experimental results show that it outperforms other methods, especially when the conditioning set is large or the sample size is not very large, in which case other methods encounter difficulties.},
  booktitle = {Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
  pages     = {804â€“813},
  numpages  = {10},
  location  = {Barcelona, Spain},
  series    = {UAI'11}
}
